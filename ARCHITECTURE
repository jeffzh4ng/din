# Architecture
This is a high-level document which talks about topics around hardware/software
codesign such as different execution models and the semantic gap between high
level languages and instruction set architectures.

For more specifics on source/target languages, compiler construction techiques
such as parsing and generation, or uarch principles such as pipelining and memory
hierarchy, take a look at [COMPILER](./COMPILER) or [CHIP](./CHIP).

**Contents**
1. Preface
2. Execution Models
3. Semantic Gap

### 1. Preface
We solve high level problems by writing programs in which universal turing machines
interpret. In this timeline of the world, our physical machines are implemented
such that they orchestrate electrons to simulate nand calculus, rather than lambda.
However, because the two calculi can encode each other (isomorphism), they share
the same semantics.

Compilers and chips act in unison in order to bridge the semantic chasm that lies
between our high level thought and our low level electron cousins. The difference
between a compiler and a chip is that of function: a compiler translates while
a chip evaluates. Yes, a chip is really just an interpreter[0] implemented with gates.
If you write a software interpreter, you're simulating on a simulator. This is the
intuition why software interpreted languages are slower. Note that this axis is
orthogonal from source language features. You can have a language with static
types that is interpreted, and one with dynamic types that is compiled. With
engineering, the line always blurs â€” we even have JIT compilation.

--------------------- <-- SaaS: Web app, Mobile app
| Problem           |
--------------------- <-- ADT/AA: Sequences, Trees, Graphs
| Algorithm         |
--------------------- <-- HLL: C/C++/Java/Python        Runtime: Unix/Linux
| Compiler & OS     |
--------------------- <-- ISA: x86/ARM/RISC-V
| Microarchitecture |
--------------------- <-- RTL: Verilog/VHDL
| Gates             |
---------------------
| Electrons         |
---------------------

**Scaling Laws**
Scaling laws such as Moore's Law, Dennard Scaling, and Bell's Law are
self-prophesizing psychosocial pills that the valley swallows. We've seen better
hardware unlock new software which drives more investment into hardware such as
x86/Unix and CUDA/GPT.

                  16e9                                          * M1
                                                                * 
                                                                  
                                                              *  
                                                              *   
                                                            *    
                                                            *    
                                                            *     
                                                          **      
                                                        *        
                                                        **        
                                                      *          
                                                    **           
                                                    **            
                                                ***              
                                              ***  PDP-11              
                                            ***                   
                                        **** IBM 360                     
                                *******                          
                   1e4    ******* ENIAC                               

### 2. Execution Models
- design points
  - latency
    - hiding -> OOO?
    - reduction -> branch prediction
    - this collection of features: CPU
    - ILP: implicit
  - throughput
    -- Throughput-optimized computing doesn't want to waste any work, and instead has 10x SMT to have many, many threads ready to do work while waiting for branches / memory / etc. etc.

- cpus, implicit ilp (hardware has complexity): moore's law and dennard scaling slowing down
- gpus, explicit dlp, tlp (programmer has complexity): amdahl's law caps perf benefits
  - flynn's taxonomy
    - SISD: ILP
    - SIMD: DLP
      - vector architectures
      - multimedia extensions to standard ISAs
      - GPUs
    - MISD: none??
    - MIMD
      - tightly coupled: TLP
      - loosely coupled: RLP

- single core era: hardware took care of complexity
- multi core era: hardware pushed complexity to software
  --> shared state, message passing, data flow

### 3. Semantic Gap
--------------------- <-- HLL: C/C++/Java/Python        Runtime: Unix/Linux
| Compiler & OS     |
--------------------- <-- ISA: x86/ARM/RISC-V
| Microarchitecture |
--------------------- <-- RTL: Verilog/VHDL

The model above actually turns out to be a simplified model of the computing stack.
If you zoom in, there's actually room to play around with the ISA's abstraction
level: does it get placed closer to the HLL or to the RTL? Take a look below.

----------------------- HLL: C               ----------------------- HLL: C

----------------------- ISA: x86




                                             ----------------------- ISA: RISC-V


------------------------ RTL: Verilog        ----------------------- RTL: Verilog

The design on the left has a small semantic gap, and the onen the right has a
large semantic gap. Small semantic gap designs have simple compilers, and complex
chips. Large semantic designs have complex compilers, and simple chips.

All decisions made at the ISA, uarch, and gate level are all impacted by the size
of the semantic gap, and the common collection of features at all three levels
are given a label such as "RISC" or "CISC", even though there's a lot of overlap.
This is not different from how HLL's are given paradigms such "FP" and "OOP",
even though all languages share a standard model: eager, sequential, and aliases
as values. Regardless, the major CISC ISA for the past fifty years has been
x86-64, which has dominated sever workloads. The major RISC ISA has been Armv7/v8,
which has dominated mobile workloads. din targets RISC-V, which is aims to be a
universal ISA for all workloads with its open and modular design.